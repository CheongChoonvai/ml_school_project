{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe45dbaf",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Times New Roman'; font-size: 14pt; text-align: center; margin-top: 200px;\">\n",
    "<b>OncoPredictAI: Machine Learning Framework for Global Cancer Data Analysis and Prediction</b>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<div style=\"font-family: 'Times New Roman'; font-size: 12pt; text-align: center;\">\n",
    "<i>Cheong Choonvai</i><br>\n",
    "Subject Name: Machine Learning with Python\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467429a",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "OncoPredictAI is a machine learning framework designed to analyze global cancer datasets for predicting patient outcomes and optimizing treatment strategies. The project integrates advanced ML models to address challenges in cancer risk assessment, treatment optimization, and resource allocation. The system is adaptable for use in diverse healthcare environments, including resource-constrained settings, and aims to provide interpretable insights for healthcare professionals worldwide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8de8f",
   "metadata": {},
   "source": [
    "## Societal or Industrial Impact\n",
    "\n",
    "OncoPredictAI advances cancer care by enabling data-driven risk assessment, optimizing treatment selection, and improving resource allocation. The system supports clinical decision-making, identifies global cancer patterns, and provides accessible analytics for both advanced and resource-limited healthcare settings. Its deployment can lead to improved patient outcomes, reduced healthcare costs, and enhanced understanding of cancer epidemiology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4544641",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "- What combinations of risk factors most accurately predict cancer severity and survival outcomes?\n",
    "- What patterns in global cancer data reveal regional differences in cancer types, treatment effectiveness, and patient outcomes?\n",
    "- What machine learning approaches best capture the complex relationships between patient characteristics and cancer progression?\n",
    "- What features provide the most predictive power for treatment cost estimation?\n",
    "- What clustering methods can identify previously unknown patient subgroups?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cde085",
   "metadata": {},
   "source": [
    "## Approach to Research Questions\n",
    "\n",
    "The project follows a comprehensive ML pipeline: data acquisition, preprocessing, exploratory analysis, feature engineering, model development, evaluation, and visualization. Diverse global datasets are harmonized and analyzed using clustering (K-means), dimensionality reduction (PCA), and predictive models (Random Forest, XGBoost). Cross-validation and robust evaluation metrics ensure model reliability and generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfb069",
   "metadata": {},
   "source": [
    "## Individual Contribution\n",
    "\n",
    "[Describe your specific contributions, e.g.:]\n",
    "- Implemented data preprocessing and feature engineering pipelines\n",
    "- Developed custom K-means and PCA modules\n",
    "- Built and tuned predictive models (Random Forest, XGBoost)\n",
    "- Created visualizations and evaluation scripts\n",
    "- Contributed to project documentation and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387e71f",
   "metadata": {},
   "source": [
    "## Dataset Details and Visualizations\n",
    "\n",
    "The primary dataset is the Global Cancer Patients Dataset (2015-2024), containing 50,000 patient records with demographics, risk factors, cancer types, treatment costs, and outcomes. Visualizations include:\n",
    "\n",
    "- ![Cancer Data Overview](../outputs/figures/cancer_data_overview.png)\n",
    "- ![PCA Visualization](../outputs/figures/cancer_data_pca.png)\n",
    "- ![K-means Clusters](../outputs/figures/kmeans_clusters.png)\n",
    "- ![K-means Elbow](../outputs/figures/kmeans_elbow.png)\n",
    "\n",
    "These plots illustrate data distributions, dimensionality reduction, and clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01903fe4",
   "metadata": {},
   "source": [
    "## Context and Background of Dataset\n",
    "\n",
    "The Global Cancer Patients Dataset aggregates international cancer statistics, including patient demographics, risk factors, and treatment outcomes. It enables cross-regional analysis and supports the development of models tailored to diverse healthcare systems. The dataset is sourced from Kaggle and is suitable for both clustering and predictive modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab05fb9",
   "metadata": {},
   "source": [
    "## Machine Learning Model and Justification\n",
    "\n",
    "The primary models used are K-means for patient segmentation, PCA for dimensionality reduction, and Random Forest/XGBoost for severity and survival prediction. These models were chosen for their interpretability, robustness to noisy data, and suitability for high-dimensional, heterogeneous healthcare datasets. Ensemble methods further improve prediction reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a16bf",
   "metadata": {},
   "source": [
    "## Alternative Models\n",
    "\n",
    "Alternative models considered include LightGBM (for resource optimization), ARIMA/Prophet (for time series forecasting), and federated learning (for privacy-preserving multi-center modeling). The final model selection prioritized interpretability, efficiency, and adaptability to resource-constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc31971",
   "metadata": {},
   "source": [
    "## Evaluation Techniques\n",
    "\n",
    "Evaluation metrics include accuracy, precision, recall, F1-score (classification), MAE, RMSE, R-squared (regression), and silhouette score (clustering). Cross-validation and holdout sets are used to assess model generalizability. Model performance is compared across different patient subgroups and healthcare settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ea422",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Hyperparameters are optimized using Bayesian optimization and grid search. For example, Random Forest and XGBoost parameters such as max_depth, learning_rate, and n_estimators are tuned to balance performance and computational efficiency. Specialized configurations are used for survival analysis and resource allocation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25686372",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "The models achieve high predictive accuracy:\n",
    "- XGBoost: AUC-ROC > 0.85 for severity prediction\n",
    "- Ensemble methods: C-index > 0.80 for survival prediction\n",
    "- Random Forest: 75% accuracy for treatment response\n",
    "- K-means/PCA: Identification of novel patient subgroups and risk factors\n",
    "\n",
    "Performance is validated across multiple regions and patient demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c505c",
   "metadata": {},
   "source": [
    "## Underfitting and Overfitting Assessment\n",
    "\n",
    "Learning curves, cross-validation results, and regularization techniques are used to assess underfitting and overfitting. Early stopping and feature selection help prevent overfitting, while model complexity is adjusted to ensure generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990b34b",
   "metadata": {},
   "source": [
    "## Key Learnings\n",
    "\n",
    "- Integrating diverse cancer datasets improves model robustness\n",
    "- Feature engineering and dimensionality reduction are critical for high-dimensional data\n",
    "- Interpretable models build trust with clinical users\n",
    "- Cross-regional validation is essential for global applicability\n",
    "- Automated pipelines enhance reproducibility and scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46367f",
   "metadata": {},
   "source": [
    "## Potential Usefulness\n",
    "\n",
    "OncoPredictAI can support healthcare providers in early cancer detection, treatment planning, and resource allocation. Its adaptability makes it valuable for both advanced and resource-limited settings, with potential for integration into national cancer registries and hospital systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50431328",
   "metadata": {},
   "source": [
    "## Future Intentions\n",
    "\n",
    "Future work includes integrating medical imaging data (e.g., X-ray), expanding to additional cancer types, developing interactive dashboards, and publishing research findings. The system may be extended to other diseases and adapted for regional healthcare needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bc4bb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "OncoPredictAI demonstrates the power of machine learning for global cancer data analysis. The project delivers actionable insights for clinicians and policymakers, with a scalable architecture for future enhancements and broader healthcare impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5729d6c",
   "metadata": {},
   "source": [
    "## Code Implementation\n",
    "\n",
    "Below are key code snippets from the project. For full code, see the project repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8396b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing Example\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('data/global_cancer_patients_2015_2024.csv')\n",
    "# Handle missing values\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "X_scaled = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Clustering Example\n",
    "from models.clustering.kmeans import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters)\n",
    "plt.title('K-means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Example\n",
    "from models.dimensionality_reduction.pca import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "pca.plot_explained_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Example\n",
    "from models.classification.random_forest import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['Target_Severity_Score'], test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6815ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model Example\n",
    "from models.classification.xgboost_model import XGBoostClassifier\n",
    "\n",
    "xgb = XGBoostClassifier(n_estimators=500, learning_rate=0.01, max_depth=8)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print('XGBoost Accuracy:', accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e762512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Metrics Example\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Example\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [6, 8, 10], 'n_estimators': [100, 200, 500]}\n",
    "gs = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy')\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best Params:', gs.best_params_)\n",
    "print('Best Score:', gs.best_score_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
